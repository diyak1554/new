{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08527d10-9aeb-44ba-a0d7-07fc9b3f4e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized corpus:\n",
      "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "['love', 'natural', 'language', 'processing', 'and', 'machine', 'learning']\n",
      "['word', 'embeddings', 'help', 'capture', 'semantic', 'relationships']\n",
      "['the', 'fox', 'is', 'clever', 'and', 'quick']\n",
      "['dogs', 'are', 'loyal', 'and', 'friendly', 'animals']\n",
      "['machine', 'learning', 'models', 'improve', 'with', 'more', 'data']\n",
      "\n",
      "Top 5 words similar to 'fox':\n",
      "  semantic (distance: 0.0088)\n",
      "  word (distance: 0.0090)\n",
      "  natural (distance: 0.0096)\n",
      "  are (distance: 0.0099)\n",
      "  language (distance: 0.0101)\n",
      "\n",
      "Top 5 words similar to 'machine':\n",
      "  friendly (distance: 0.0068)\n",
      "  the (distance: 0.0092)\n",
      "  are (distance: 0.0092)\n",
      "  learning (distance: 0.0095)\n",
      "  capture (distance: 0.0095)\n",
      "\n",
      "Top 5 words similar to 'dog':\n",
      "  loyal (distance: 0.0092)\n",
      "  love (distance: 0.0104)\n",
      "  and (distance: 0.0106)\n",
      "  relationships (distance: 0.0108)\n",
      "  dogs (distance: 0.0115)\n",
      "\n",
      "Top 5 words similar to 'language':\n",
      "  fox (distance: 0.0101)\n",
      "  semantic (distance: 0.0101)\n",
      "  data (distance: 0.0106)\n",
      "  the (distance: 0.0110)\n",
      "  learning (distance: 0.0111)\n",
      "\n",
      "Top 5 words similar to 'quick':\n",
      "  relationships (distance: 0.0088)\n",
      "  natural (distance: 0.0097)\n",
      "  data (distance: 0.0100)\n",
      "  the (distance: 0.0105)\n",
      "  jumps (distance: 0.0105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def load_corpus():\n",
    "    corpus = [\n",
    "        \"The quick brown fox jumps over the lazy dog\",\n",
    "        \"I love natural language processing and machine learning\",\n",
    "        \"Word embeddings help capture semantic relationships\",\n",
    "        \"The fox is clever and quick\",\n",
    "        \"Dogs are loyal and friendly animals\",\n",
    "        \"Machine learning models improve with more data\",\n",
    "    ]\n",
    "    tokenized = [simple_preprocess(doc) for doc in corpus]\n",
    "    return tokenized\n",
    "\n",
    "def train_word2vec(tokenized_corpus, vector_size=50, window=3, min_count=1):\n",
    "    model = Word2Vec(\n",
    "        sentences=tokenized_corpus,\n",
    "        vector_size=vector_size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=1,\n",
    "        seed=42\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_faiss_index(word_vectors):\n",
    "    dim = word_vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(word_vectors)\n",
    "    return index\n",
    "\n",
    "def query_similar_words(model, index, word, top_k=5):\n",
    "    if word not in model.wv:\n",
    "        print(f\"Word '{word}' not in vocabulary.\")\n",
    "        return\n",
    "\n",
    "    query_vec = model.wv[word].reshape(1, -1).astype(np.float32)\n",
    "    distances, indices = index.search(query_vec, top_k + 1)\n",
    "\n",
    "    print(f\"\\nTop {top_k} words similar to '{word}':\")\n",
    "    for dist, idx in zip(distances[0][1:], indices[0][1:]):\n",
    "        similar_word = model.wv.index_to_key[idx]\n",
    "        print(f\"  {similar_word} (distance: {dist:.4f})\")\n",
    "\n",
    "def run_pipeline():\n",
    "    tokenized_corpus = load_corpus()\n",
    "    print(\"Tokenized corpus:\")\n",
    "    for sent in tokenized_corpus:\n",
    "        print(sent)\n",
    "\n",
    "    model = train_word2vec(tokenized_corpus)\n",
    "    word_vectors = model.wv.vectors.astype(np.float32)\n",
    "    faiss_index = build_faiss_index(word_vectors)\n",
    "\n",
    "    query_words = ['fox', 'machine', 'dog', 'language', 'quick']\n",
    "    for word in query_words:\n",
    "        query_similar_words(model, faiss_index, word)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b30f43-cb5c-450b-9af9-d17aa32a71f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp313-cp313-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\server\\appdata\\roaming\\python\\python313\\site-packages (from gensim) (2.3.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\server\\appdata\\roaming\\python\\python313\\site-packages (from gensim) (1.16.0)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.4.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\server\\appdata\\roaming\\python\\python313\\site-packages (from smart_open>=1.8.1->gensim) (1.17.3)\n",
      "Downloading gensim-4.4.0-cp313-cp313-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/24.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.4 MB 2.1 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.3/24.4 MB 2.5 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.8/24.4 MB 2.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 2.6/24.4 MB 3.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 3.7/24.4 MB 3.3 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 5.0/24.4 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.3/24.4 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.9/24.4 MB 4.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.7/24.4 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.3/24.4 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.1/24.4 MB 5.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.4/24.4 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.4/24.4 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.5/24.4 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.5/24.4 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.3/24.4 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.1/24.4 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.1/24.4 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.9/24.4 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.7/24.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.3/24.4 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.4 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.1/24.4 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 4.6 MB/s  0:00:05\n",
      "Downloading smart_open-7.4.2-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: smart_open, gensim\n",
      "\n",
      "   ---------------------------------------- 0/2 [smart_open]\n",
      "   ---------------------------------------- 0/2 [smart_open]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   ---------------------------------------- 2/2 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.4.0 smart_open-7.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1177a948-5aa8-4ce6-88f1-d562aec4c36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\server\\appdata\\roaming\\python\\python313\\site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54334243-9525-4692-9059-ea0c8e6c5e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
